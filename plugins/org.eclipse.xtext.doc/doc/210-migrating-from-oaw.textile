
h1(#from_oaw_to_tmf). From oAW to TMF

TMF Xtext is a complete rewrite of the Xtext framework previously released with openArchitectureWare 4.3.1 (oAW). We refer to the version from oAW as oAW Xtext whereas the current Xtext version will be called TMF Xtext to avoid misconceptions.
oAW Xtext has been around for about 2 years before TMF Xtext was released in June 2009 and has been used by many people to develop little languages and corresponding Eclipse-based IDE support.

TODO: Motivate migration from oAW to TMF with reference to new features

This document describes the differences between oAW Xtext and TMF Xtext and is intended to be used as a guide to migrate from oAW Xtext to TMF Xtext.
For people already familiar with the concepts of oAW Xtext it should also serves as a shortcut to learn TMF Xtext.  

h2(#why_rewrite). Why a rewrite?

The first thing you might wonder about is why we decided to reimplement the framework from scratch as opposed to use the existing code base and enhance it further on. 
We decided so because we had learned a lot of lessons from oAW Xtext. On the other hand we wanted to stick with many proven concepts 
but found the implementation was lacking a solid foundation (the author of these lines is the original author of that non-solid code btw. :-)). The first version of oAW Xtext was just a proof of concept but was so well received that it had been extended with all kinds of features (some were good, some were bad). Unfortunately code quality, clean and orthogonal concepts and test coverage did not receive the needed focus.

In addition to this aspects of quality, oAW Xtext suffers from some severe performance problems. The naive use of Xtend (see next section) prevented us to use oAW Xtext for growing real-world models.

h2(#migration_overview). Migration overview

Although a couple of things have changed we tried to keep good ideas and left many things unchanged. At the same time we wanted to clean up wrong concepts and solve the main problems we and you had with oAW Xtext.
From a bird's eye view if you want to migrate an existing oAW Xtext project to TMF Xtext, you mainly just need to rename the old grammar from *.xtxt to *.xtext and add two lines to the beginning of that document (see below for details). You might also have to change a few keywords, but all in all this is pretty easy and we've migrated a couple of oAW Xtext projects this way without problems.
The other aspect where lots of code might have been written for is validation. In oAW Xtext we used Xpand's Check language to define constraints on the meta model. Even though this has been one major reason for the lack of scalability in Xtext we decided to keep the Check language as an option for compatibility reasons. Therefore, you do not need to translate your existing checks to a different language. Even better, you can overcome some performance issues by leveraging the newly introduced hooks to control the time of validation (while you type, on save, or on triggering an explicit action). See the validation section below. 
Anyway, if you want to provide a slick user experience validation should run fast while you type. Therefore, we strongly encourage you to consider implementing validation using our declarative Java approach (TODO: ref).

We've developed and reviewed a lot of oAW Xtext projects and saw that most of the work was done in the grammar and in the validation view point. 
Other aspects such as outline view, label provider or content assist have been customized too, but they usually do not contain complicated Xtend code.
One exception was linking and content assist which in oAW Xtext contains a lot of duplicated code. While working on this we came up with a new concept called "scopes" that not only streamlines implementation in terms of redundancy. Scopes also increase the overall performance of Xtext.
But since the concept of scopes was not carved out in oAW Xtext one usually implemented a cluttered and duplicated poor copy through linking and content assist. For obvious reasons, we didn't manage to come up with a good compatibility layer.
So this is where most of the migration effort will go into. But we think the notion of scopes is such a valuable addition that it is worth the refactoring. Also, when looking at existing oAW Xtext projects we found that most projects didn't change the default linking that much or they came up with their own linking framework anyway.

However, if we have completely misunderstood the situation and your oAW Xtext project cannot be migrated in a reasonable amount of time, please tell us. We want to help you!

h2(#Xtend_based_apis). Where are the Xtend-based APIs?

One of the nice things with oAW Xtext was the use of Xtend to allow customizing different aspects of the generated language infrastructure.
Xtend is a part of the template language Xpand, which is shipped with oAW (and now is included in M2T Xpand).  It provides nicer expression syntax than Java.
Especially the existence of higher-order functions for collections is extremely handy when working with models.
In addition to the nice syntax, it provides dynamic polymorphic dispatch, which means that declaring e.g. label computation for a meta model is very convenient and type safe at the same time.
In contrast using Java one usually has to write instanceof and cast orgies. 

h3(#Xtend_is_hard_to_debug). Xtend is hard to debug

While the aforementioned features allow the convenient specification of label and icon providers, outline views, content assist and linking. Xtend is interpreted and therefore hard to debug. Because of that Xpand is shipped with a special debugger facility. Unfortunately, the shipped debugger cannot be used in the context of Xtext since it implies that the Xtend functions have to be called from a workflow. This is not and cannot be the case for Xtext Editors.
As a result one has to debug his way through the interpreter, which is hard and inconvenient (even for us, who have written that interpreter).

h3(#Xtend_is_slow). Xtend is slow

But the problematic debugging was not the main reason why there are no Xtend-based APIs beside Check in TMF Xtext. The main reason is that Xtend is too slow to be evaluated "inside" the editor, that is evaluating lots of Xtend code while you type. 
While Xtend's performance is sufficient when run in a code generator, it is just too slow to be executed on keystroke (or 500ms after the last keystroke, which is when the reconciler reparses, links and validates the model). Xtend is relatively slow, because it supports polymorphic dispatch (the cool feature mentioned above), which means that for each invocation it matches at runtime which function is the best match and it has to do so on each call. Also Xtend supports a pluggable typesystem, where you can adapt to other existing type systems such as JavaBeans or Ecore. This is very powerful and flexible but introduces another indirection layer. Last but not least the code is interpreted and not compiled. The price we pay for all these nice features is reduced performance.

In addition to these scalability problems we have designed some core APIs (e.g. scopes) around the idea of Iterables, which allows for lazy resolution of elements. As Xtend does not know the concept of Iterators you would have to work with lists all the time. This is far more expensive than chaining Iterables through filters and transformers like we do with Google Collections in TMF Xtext.

h3(#Convenient_Java). Convenient Java

To summarize this we had to find a way to allow for convenient, scalable and debuggable APIs. Ultimately we wanted to provide neat DSLs for every view point, which provide all these things. However, we had to prioritize our efforts with the available resources in mind. 
As a result we found ways and means to tweak Java as good as possible to allow for relatively convenient, high performing implementations. 

Java is fast and can easily be debugged but ranks behind Xtend regarding convenience. We address this with different approaches to make Java development in text context of Xtext as comfortable as possible.

Most of the APIs in TMF Xtext use polymorphic dispatching, which mimics the polymorphic dispatch known from Xtend. Another valuable feature of Xtend while working with oAW Xtext is static type checking while working with the inferred metamodel whereas In Java the work with dynamic ecore classes was rather cumbersome. Since TMF Xtext generates static ecore classes per default you get back static typing in Java as well. The use of "Google Collections":http://code.google.com/p/google-collections reduces the pain when navigating over your model to extract information. 
 
With these techniques an ILabelProvider that handles your own EClasses Property and Entity can be written like this:

bc.. 
public class XtextLabelProvider extends DefaultLabelProvider {

  String label(Entity e) {
    return e.getName();
  }

  String image(Property p) {
    return p.isMultiValue() ? "complexProperty.gif": "simpleProperty.gif";
  }

  String image(Entity e) {
    return "entity.gif";
    // TOOD: think of a nice way to introduce google collections
    // e.g. e.properties.typeselect(Reference).empty ? value object : entity
  }

}
  
p. As you can see this is very similar to the way one describes labels and icons in oAW Xtext, but has the advantage that it is easier to test and to debug, faster and can be used everywhere an ILabelProvider is expected in Eclipse.

h3(#conclusion). Conclusion

Just to get it right, Xtend is a very powerful language and we still use it for it's main purpose: code generation and model transformation. The whole generator in TMF Xtext is written in Xpand and Xtend and it's performance is at least in our experience sufficient for that use case. Actually we were able to increase runtime performance of Xpand by about 60% for the Galileo release of M2T Xpand. But still, live execution in the IDE and on typing is very critical and one has to think about every millisecond in this area. 

As an alternative to the Java APIs we also considered other JVM languages. We like static typing and think it is especially important when processing typed models (which evolve heavily). That's why Groovy or JRuby were no alternative. Using Scala would have been a very good match, but we didn't want to require knowledge of Scala so we didn't use it and stuck to Java. 

h2(#differences). Differences

In this section differences between oAW Xtext and TMF Xtext are outlined and explained. We'll start from the primary APIs such as the grammar language and the validation hook and finish with the different secondary hooks for customizing linking and several UI aspects, such as outline view and content assist. We'll also try to translate/map some of the oAW Xtext concepts to their counterparts from TMF Xtext.

h3(#differenced_grammar_language). Differences in the grammar language

When looking at a TMF Xtext grammar the first time it looks like one has to provide additional information which was not necessary in oAW Xtext. In oAW Xtext *.xtxt files started with the first production rule where in TMF Xtext one has to declare the name of the language followed by declaration of one or more used/generated meta models:

TMF Xtext heading information

bc.. 
  grammar my.namespace.Language with org.eclipse.xtext.common.Terminals
  generate myDsl "http://www.namespace.my/2009/MyDSL"
 
  FirstRule : ...

p. In oAW Xtext this information was provided through the generator (actually it is contained in the *.properties file) but we found that these things are very important for a complete description of a grammar and had therefore be part of the grammar in order to have self-describing grammars and allow for sophisticated static analysis, etc.. 

Apart from the first two lines the grammar languages of both versions are more or less compatible. The syntax for all the different EBNF concepts (alternatives, groups, cardinalities) is similar.
Also assignments are syntactically and semantically identical in both versions. 
However in TMF Xtext some concepts have been generalized and improved:

h4(#differences_datatype_rules). String rules become Datatype rules

The very handy String rules are still present in TMF Xtext but we generalized them so that you don't need to write the 'String' keyword in front of them and at the same time these rules can not only produce EStrings but (as the name suggests) any kind of EDatatype. Every parser rule that does include assignments or calls any that does returns an EDataType containing the consumed data. Per default this is an EString but you can now simply create a parser rule returning other EDatatype as well (see TODO-REF).

bc. 
  Float returns ecore::EDouble : INT ('.' INT)?;

h4(#differences_enum_rules). Enum rules

Enum rules have not changed significantly. The keyword has changed to be all lower case ('enum' instead of 'Enum').
Also the right handside of the assignment is now optional. That is in oAW Xtext:

bc.. 
  Enum MyEnum : foo='foo' | bar='bar';
  
p. becomes

bc.. 
  enum MyEnum : foo='foo' | bar='bar';
   
p. and because the name of the literal equals the literal value one can ommit the right handside in this case and write:

bc.. 
  enum MyEnum : foo | bar;

h4(#differences_native_rules). Native rules

The most significant improvement to oAW Xtext is that we could replace the blackbox native rules with full-blown EBNF syntax. 
That is native rules become terminal rules and or no longer written as a string literal containing ANTLR syntax but are a part of the language.

Example :

bc. 
  Native FOO : "'f' 'o' 'o'";

p. becomes

bc. 
  terminal FOO : 'f' 'o' 'o';

p. See the reference documentation for all the different expressions possible in terminal rules (TODO-REF).

h4(#differences_no_URI_token). No URI terminal rule anymore

Although with grammar-mixins we would have been able to implement the URI terminal rule again, we decided to remove it. The only reason for the URI token was to mark the model some how so that the framework knows what information to use in order to load referenced models. Instead we decided to solve this similar to how we imply other defaults: by convention.

So instead of using a special token which is syntactically a STRING token, the default import mechanism now looks for EAttributes of type EString with the name 'importedURI'.
That is if you've used the URI token like so:

bc. 
  Import : 'import' myReference=URI;

you'll have to rewrite it like so

bc. 
  Import : 'import' importedURI=STRING;

Although this changes your meta model, one usually never used this reference explicititely as it was only there to be used by the default import mechanism. So we assume and hope that changing the reference is not a big deal for you. 

h4(#differences_return_types). Return types

The syntax to explicitly declare the return type of a rule has changed. In oAW Xtext (where this was marked as 'experimental') the syntax was like so:

bc. 
  MyRule [MyType] : foo=ID;  

in TMF Xtext we have a keyword for this :

bc. 
  MyRule returns MyType : foo=ID;

This is a bit more verbose, but at the same time more readable. And as you don't have to write the return type in most situations, it's good to have a more explicit, readable syntax.


h3(#differences_validation). Differences in Validation

TMF Xtext still supports implementing validation using Xpand's check. However it is no longer using the EMF meta model (typesystem) but now uses the JavaBeansMetamodel.
This requires minor changes (namely the namespaces to be imported are now the qualified name of the generated Java classes). 
Example: If your check file looked like this in oAW Xtext :

bc. 
  import myMetamodel;
  context Type ERROR "foo" : name!=null;   

it becomes something like the following in TMF Xtext :

bc. 
  import my::pack::to::myMetaModel;
  context Type ERROR "foo" : name!=null;

Where @my::pack::to::myMetaModel@ refers to the package the generated EClasses are in. In other words there's a Java class @my.pack.to.myMetaModel.Type@.
We changed this in order to allow use of any Java API , such as ${org.eclipse.xtext/src/org.eclipse.xtext.scoping.IScopeProvider}, from within Check and Xtend.

h3(#differences_linking). Differences in Linking

The linking has been completely redesigned. In oAW Xtext linking was done in a very naive way: To find an element one queries list of all 'visible' EObjects, then filters out what is not needed and tries to find a match by comparing the text written for the crosslink with the value returned by the id() extension. As a side-effect of link_feature() the reference is then set.

The code about selecting and filtering allElements() usually has been duplicated in the corresponding content assist function, so that linking an content assist are semantically in sync. If you're good (we usually were not) you externalized that piece of code and reused the same extension in content assist and linking. 

To put it blunty this approach could be summarized in two steps:
# Give me the whole universe including every unregarded object in the uncharted backwaters of the unfashionable end of the western spiral arm of the galaxy 
# From this, select the one I need

This was not only very expensive but also lacks an important abstraction: the notion of scopes.

h4(#differences_linking_sopes). The idea of scopes

In TMF Xtext we've introduced scopes and scope providers that are responsible for creating scopes. A scope is basically a set of name->value pairs. Scopes are implemented upon Iterables and are nested to build a hierarchy. With scopes we declare "visible" objects in a lazy and cost-saving way where the linker only navigates as far as necessary to find the needed objects. The content assist reuses this set of visible objects to offer only objects that can be linked. 

When implementing custom linking scoping is where most of the semantics typically goes into. By implementing an ${org.eclipse.xtext/src/org.eclipse.xtext.scoping.IScopeProvider} for your language linking and content assist will automatically be kept in sync since both rely and use the scope provider.

The provided default implementation is semantically mostly identical to how the default linking worked in oAW Xtext: 
# Elements which have an attribute 'name' will be made visible by their name,
# Referenced resources will be put on the (outer) scope by using the 'importedURI'- naming convention (TODO-REF) and will only be navigated to if necessary
# The available elements are filtered by the expected type (i.e. the type of the reference to be linked)

h4(#differences_linking_migration). Migration

We expect the migration of linking to be very simple if you've not changed the default semantics that much. We've already migrated a couple of projects and it wasn't too hard to do so.
If you have changed linking (and also content assist) a lot, you'll have to translate the semantics to the IScopeProvider concept. This might a bit of work, but it is worth the effort as this will clean up your code base and better separate concerns.

h3(#differences_ui). Differences in UI customizing

In oAW Xtext several UI services such as content assist, outline view or the label provider have been customized using Xtend. In TMF Xtext there is no Xtend API for these aspects. Extensive model computations for the content assist is most probably not necessary anymore- it reuses scopes. And since we provide a declarative Java API that mimics the polymorphic dispatch and relies on static ecore classes you will gain nearly the same expressiveness as before while increasing maintainability and performance.

Beside the API change in favor of Java we have to mention that in TMF Xtext the outline view does not support multiple view points so far. This is just because we didn't manage to get this included (due to low priorization). We don't think that view points are a bad idea in general, but we decided that other things were more important.

h2. Migration Support

In this document we tried to explain why we decided to change some aspects of Xtext's architecture. We consider most changes as minor but in the case of scopes you will face a conceptual break. We tried to explain why it is not easily possible to come up with an adapter for the notion of the latter.

That said you might not have the time to do the migration and wished to have advice for migrating, especially from oAW linking to TMF linking. You're welcome to ask any questions in the newsgroup and we'll try to help you as much as possible in order to get your projects migrated. Also, if you don't want to do the migration yourself we (itemis AG) can do the work or help you with that. 
  
h2. Catch Basin

The following sections have been removed from somewhere else but should not be completely removed, yet.

h4(#google_collections). Google Collections

The other thing we love about Xtend is its convenient way to navigate a model. This is something which can't be done with Java, as it lacks closures and in general requires to write lots of boilerplate such as superfluos type information, etc. So this is where we have to make some compromises.
Anyway, we think we could improve this a bit by using Google Collections which is (the name suggests it) a collections framework written by some google guys. It's open-source and there's a JSR proposing to add the framework to the JDK, which would IOHO be a very good addition.

It provides lots of nice static factory methods similar to what we have in java.util.Collections and java.util.Arrays, contains higher-order functions based on a function type included in the library and a couple of very good collection implementations such as multi maps and immutable implementations of the various collection types. 
With this, for instance, one can write a chain of filters and transformers like so:

bc.. 
  ArrayList<String> names = newArrayList("foo", "bar", "honk");
  Iterable<String> filtered = filter(names, not(isEqualTo("bar")));
  Iterable<Integer> lengths = transform(filtered,new Function<String, Integer>() {
    public Integer apply(String from) {
      return from.length();
    }
  });

p. or in a more functional way :

bc.. 
  transform(
    filter(
      newArrayList("foo", "bar", "honk"), 
        not(isEqualTo("bar"))
      ),
      new Function<String, Integer>() {
        public Integer apply(String from) {
          return from.length();
        }
      }
    );

p. From a syntactical point of view Google Collections is in no way a replacement for real closures and a non-verbose expression language like we have in Xtend, but it's a big improvement over traditional Java programming with java.util.* and it performs much better than Xtend.

h4(#differences_grammar_improvements). General Improvements

Aside the improvements already mentioned previously some noteworthy new things added to the grammar language are:

h4(#differences_no_builtin_terminals). No built-in terminals

In oAW Xtext common terminals like ID, INT, STRING, ML_COMMENT, SL_SOMMENT and WS (whitespace) were hard coded into the grammar language and couldn't be removed.
Also overriding was error-prone and challenged. In TMF Xtext these terminals are imported through the newly introduced grammar mixin mechanism. This means that they are still there but they are now libraries. You don't have to use them and you can come up with your own reusable rules. 
This is what the @with org.eclipse.xtext.common.Terminals@ part is about. It imports the common terminal rules.

h5(#differences_grammar_mixins). Grammar mixins

Grammar mixins allows you to extend existing languages and change their concrete and abstract syntax. However the abstract syntax (i.e. the ecore model) can only be extended. This allows you to reuse existing validations, code generators, interpreters or other code which has been written against those types. We eat our own dogfood and have introduced a common.Terminals grammar which defines the terminal rules, which in oAW Xtext have been hard-coded into the grammar language.

h5(#differences_import_ecore_model). Reuse existing ecore models

In oAW Xtext reusing existing ecore models didn't work well and we communicated this by flagging the feature as 'experimental'. In TMF Xtext importing existing ecore models is fully supported. Moreover it is possible to import a couple of different EPackages and generate some at the same time, so that the generated ecore models extend or refer to the existing ecore models.

h4(#differences_validation_lifecycles). Validation Lifecycles

In order to make more expensive validations possible without slowing down the editor, TMF Xtext supports three different validation hooks.
# FAST constraints are executed in the reconciler (i.e. 500 ms after the last keystroke) and on save.
# NORMAL constraints are executed on save only.
# EXPENSIVE constraints are executed through an action which is available through the context menu.

Please note that when using Xtext models for code generation the checks of all three categories will be performed. 

h4. Validation

In addition to the switch to the JavaBeans metamodel it is now possible to add information about the feature which is validated:

bc. 
  context Entity#name ERROR "Name should start with a capital "+this.name+"." :
    this.name.toFirstUpper() == this.name;

If you add the name of a feature prepended by a hash ('#'), in the editor only the value of the feature will be marked, not the whole object.


h5(#differences_actions). Actions

The grammar language gained one new concpet important when writing left-factored grammars (e.g. expressions). In oAW Xtext one usualy wrote something like the following:

bc.. 
  Addition  : left=Multi ('+' right=Addition)?;
  Multi     : left=Expr ('*' right=Multi)?;
  Expr      : IntLiteral | '(' Addition ')';
  IntLiteral: value=INT;
  	
p. This is a working grammar, but the problem is that the resulting ecore model is not like you want it to look and more important the model created by the parser contains a lot of redundant information.
For instance the expression @(3)@ would be parsed into the following model:

bc.. 
Addition {
  left=Multi {
    left=Addition {
      left=Multi {
        left=IntLiteral {
          value=3
        }
      }
    }
  }
}
p.  This is of course not what you want or expect. Also the structure of the generated ecore model is not how one usually wants it to look like.
We solved this in TMF Xtext by introducing a new concept: Actions. With actions one can do minor AST rewritings within a rule. For example in TMF Xtext above's expression language should be defined like this:

bc.. 
  Addition  : Multi ({Addition.left=current} '+' right=Multi)*;
  Multi     : Expr  ({Multi.left=current) '*' right=Expr)*;
  Expr      : IntLiteral | '(' Addition ')';
  IntLiteral: value=INT;
  
p. Actions are enclosed in curly braces and follow the syntax 

bc.. '{' type=[EClass] '.' feature=[EReference] ('='|'+=') 'current' '}'

p. You can think of it as a short form of the following Java code:

bc.. 
  temp = current;
  current = new MyType();
  current.setMyReference(temp);
